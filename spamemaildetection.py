# -*- coding: utf-8 -*-
"""SpamEmailDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZz84clXrzi8_A45Tk9xb4Ld7_5uXG5m

DATASET IMPORTING
"""

!pip install chardet
!pip install scikit-learn

import chardet

with open('/content/spam.csv', 'rb') as f:
    encoding = chardet.detect(f.read())['encoding']

import pandas as pd

raw_data_set = pd.read_csv('/content/spam.csv', encoding=encoding)

data_set = raw_data_set.where((pd.notnull(raw_data_set)),'')

import nltk
import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords


nltk.download('punkt')
nltk.download('stopwords')


def process_text(text):

    tokens = word_tokenize(text)

    tokens = [word.lower() for word in tokens]

    table = str.maketrans('', '', string.punctuation)
    stripped = [w.translate(table) for w in tokens]

    stop_words = set(stopwords.words('english'))
    words = [word for word in stripped if word not in stop_words]
    return words


data_set['processed_text'] = data_set['v2'].apply(process_text)

data_set.head()

data_set.loc[data_set['v1'] == 'spam', 'v1',] = 0
data_set.loc[data_set['v1'] == 'ham', 'v1',] = 1

X = data_set['v2']
Y = data_set['v1']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=3)

"""Feature Extraction"""

